<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <title>Your Page Title</title>
</head>

<body>
    <div class="container">
        <h1>Welcome to the Medical Report Analyzer</h1>
<<<<<<< HEAD
=======
        <!-- <a href="{{ url_for('db_query') }}" class="button">Go to Database Query Interface</a> -->
>>>>>>> origin/dev_pipeline_entity_recognition

        <p>Select the conditions you want to analyze from medical reports.</p>
        <!-- Input type selection panel , select input form from txt or pdf-->
        <form action="{{ url_for('go') }}" enctype="multipart/form-data" method="post">
            <fieldset>
                <legend>Input Type</legend>
                <input accept=".csv" name="file" type="file">
            </fieldset>
<<<<<<< HEAD
            <fieldset>
                <legend>LLaMA Settings</legend>
                <label for="temperature">Prompt:</label>
                <textarea id="prompt" name="prompt">
[INST] &lt;&lt;SYS&gt;&gt;
Sie sind ein medizinischer Assistent von OpenAI ChatGPT. Im Folgenden finden Sie einen Bericht einer neuroradiologischen Intervention. Manchmal sind nicht alle Informationen angegeben. Wenn Informationen fehlen, geben Sie "null" an. Bitte extrahieren Sie die gesuchten Informationen aus dem Interventionsbericht. 
&lt;&lt;/SYS&gt;&gt;
[/INST]
Beispiel: 
Untersuchung vom 22.12.2022.

Indikation: Notfallintervention ohne vorherige schriftliche Einverständniserklärung bei rechtshemisphärieller Schlaganfallsymptomatik mit CT-angiographisch nachgewiesenem prox. M2-Verschluss bei wohl thrombosiertem Aneurysma, ASPECT = 10. Thrombektomie frustran. IV Lyse erfolgt. NihSS: 5. 

Kam es zu einer Blutung? Ja, wenn eine Blutung oder SAB beschrieben wird. Nein, wenn im Befund steht, dass keine Blutung vorliegt. 
ASSISTANT: nein

[INST]
Das ist der Interventionsbericht:
{report}

Kam es zu einer {symptom}? 
[/INST]
                </textarea>

                <label for="variables">Variables (separated by commas):</label>
                <input id="variables" name="variables" value="Headache,Cancer" type="text">

                <label for="temperature">Temperature:</label>
                <input type="number" id="temperature" name="temperature" step="0.01" min="0" max="1" value="0.7">
=======
            <fieldset>
                <legend>LLaMA Settings</legend>
                <label for="temperature">Prompt:</label>
                <textarea id="prompt" name="prompt">
[INST] &lt;&lt;SYS&gt;&gt;
Sie sind ein medizinischer Assistent von OpenAI ChatGPT. Im Folgenden finden Sie einen Bericht einer neuroradiologischen Intervention. Manchmal sind nicht alle Informationen angegeben. Wenn Informationen fehlen, geben Sie "null" an. Bitte extrahieren Sie die gesuchten Informationen aus dem Interventionsbericht.
&lt;&lt;/SYS&gt;&gt;
[/INST]
Beispiel:
Untersuchung vom 22.12.2022.

Indikation: Notfallintervention ohne vorherige schriftliche Einverständniserklärung bei rechtshemisphärieller Schlaganfallsymptomatik mit CT-angiographisch nachgewiesenem prox. M2-Verschluss bei wohl thrombosiertem Aneurysma, ASPECT = 10. Thrombektomie frustran. IV Lyse erfolgt. NihSS: 5.

Kam es zu einer Blutung? Ja, wenn eine Blutung oder SAB beschrieben wird. Nein, wenn im Befund steht, dass keine Blutung vorliegt.
ASSISTANT: nein

[INST]
Das ist der Interventionsbericht:
{report}

Kam es zu einer {symptom}?
[/INST]
                </textarea>
                <label for="variables">Variables (separated by commas):</label>
                <input id="variables" name="variables"
                        value="Headache,Cancer"
                        type="text">
                <label for="temperature">Temperature:</label>
                <input type="number" id="temperature" name="temperature" step="0.01" min="0" max="1" value="0.7">
                <label for="model">Model:</label>
                <select name="model" id="model">
                    <option value="llama-2-7b-chat.Q5_K_M.gguf">LLaMA 2 7b</option>
                </select>
            </fieldset>

            <input type="submit" value="Go!!!">
        </form>

        <!-- TODO: backend not implemented yet -->
        <!-- Report Type Filtering Panel -->
        <!-- <fieldset>
            <legend>Report Type</legend>
            <label for="report_type">Select Report Type:</label>
            <select id="report_type" name="report_type">
                <option value="radiology">Radiology</option>
                <option value="pathology">Pathology</option>
                <option value="discharge">Discharge</option>
                <option value="progress">Progress</option>
                <option value="consult">Consult</option>
                <option value="operative">Operative</option>
                <option value="other">Other</option>
            </select>
        </fieldset> -->
        <!-- llm server cofiguration panel -->
        <!-- ip address, user name, password -->
        <!-- <form action="{{ url_for('llm_server_config') }}" method="post">
            <fieldset>
                <legend>LLM Server Configuration</legend>
                <label for="ip_address">Enter IP Address:</label>
                <input id="ip_address" name="ip_address" placeholder="e.g., 192.168.33.112" type="text">
                <label for="user_name">Enter User Name:</label>
                <input id="user_name" name="user_name" placeholder="e.g., admin" type="text">
                <label for="password">Path to SSH key:</label>
                <input id="keyfile_path" name="keyfile_path" placeholder="/home/user/.ssh/id_ed25519" type="text">
                <label for="model_selection">Select LLM Model:</label>
                <select name="model_selection" id="model_selection">
                    <option value="/mnt/bulk/isabella/llamaproj/llama-2-7b-chat.Q5_K_M.gguf">LLaMA 2 7b</option>
                </select>
                <input type="submit" value="Connect">
            </fieldset>
        </form> -->

        <!-- TODO: backend not implemented yet -->
        <!-- LLM Model Selection Panel -->
            <fieldset>
                <label for="temperature">Temperature:</label>
                <input type="number" id="temperature" name="temperature" step="0.01" min="0" max="1" value="0.7">
                <input type="submit" value="Connect">
            </fieldset>
>>>>>>> origin/dev_pipeline_entity_recognition

                <label for="model">Model:</label>
                <select name="model" id="model">
                    <option value="llama-2-7b-chat.Q5_K_M.gguf">LLaMA 2 7b chat</option>
                    <option value="llama-2-70b-chat.Q5_K_M.gguf">LLaMA 2 70b chat</option>
                    <option value="llama-2-13b-chat.Q5_K_M.gguf">LLaMA 2 13b chat</option>
                    <option value="sauerkrautlm-70b-v1.Q5_K_M.gguf">LLaMA 2 70b chat sauerkraut</option>
                    <option value="em_german_70b_v01.Q5_K_M.gguf">LLaMA 2 70b chat emgerman</option>
                </select>
            </fieldset>
            <fieldset>
                <legend>Postprocessing settings</legend>
                <label for="pattern">Pattern:</label>
                <input name="pattern" value="ja|nein" type="text">
                <label for="default_answer">Default Answer:</label>
                <input name="default_answer" value="fehlt" type="text">
            </fieldset>

            <input type="submit" value="Go!!!">
        </form>
    </div>

</html>